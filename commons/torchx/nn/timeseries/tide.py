#
# Long-term Forecasting with TiDE: Time-series Dense Encoder
# https://arxiv.org/abs/2304.08424
#
# Changes respect the article:
#
#   1) because the number of input features is small, it is not necessary to apply the projection
#   2) for compatibility with the other model, 'x' passed to 'forward' is a tuple composed by 3 3D tensors:
#
#       y_past:   (N, len(ylags), ny)
#       X_past:   (N, len(xlags), nx)
#       X_future: (X, len(tlags), nx)
#

import torch
import torch.nn as nn
from torch import Tensor

from .ts import TimeSeriesModel
from ... import nn as nnx


# ---------------------------------------------------------------------------
# Residual Norm
# ---------------------------------------------------------------------------

class _ResidualBlock(nn.Module):

    def __init__(self, input_dim, output_dim, hidden_size, use_layer_norm, dropout):
        super().__init__()
        self.dense = nn.Sequential(
            nnx.Linear(input_dim, hidden_size),
            nn.ReLU(),
            nnx.Linear(hidden_size, output_dim),
            nn.Dropout(dropout),
        )
        # linear skip connection from input to output of self.dense
        self.skip = nnx.Linear(input_dim, output_dim)

        # layer normalization as output
        if use_layer_norm:
            self.layer_norm = nnx.LayerNorm(output_dim)
        else:
            self.layer_norm = None
    # end

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # residual connection
        x = self.dense(x) + self.skip(x)
        # layer normalization
        if self.layer_norm is not None:
            x = self.layer_norm(x)
        return x
    # end
# end


# ---------------------------------------------------------------------------
# TiDE model (with X_future)
# ---------------------------------------------------------------------------
# Model uses X_future
#

class TiDE(TimeSeriesModel):

    def __init__(self,
                 input_shape,
                 output_shape,
                 hidden_size=None,
                 decoder_output_size=None,
                 temporal_hidden_size=None,
                 num_encoder_layers=1,
                 num_decoder_layers=1,
                 use_layer_norm=True,
                 use_future_features=True,
                 dropout=0.1
                 ):
        """

        :param input_shape: (past_len, |y| + |X|)
        :param output_shape: (future_len, |y|)
        :param decoder_output_size: size of the data generated by the decoder
        :param temporal_hidden_size: data size of the temporal decoder hidden layer
        :param hidden_size: data size of the hidden layers in encoder and decoder blocks
        :param num_encoder_layers: n of encoder blocks
        :param num_decoder_layers: n of decoder blocks
        :param use_layer_norm: if to use the layer norm in the residual blocks
        :param use_future_features: if to use X_future (the future input features) in input
        """
        super().__init__(input_shape=input_shape,
                         output_shape=output_shape,
                         hidden_dim=hidden_size,
                         decoder_output_size=decoder_output_size,
                         temporal_hidden_size=temporal_hidden_size,
                         num_encoder_layers=num_encoder_layers,
                         num_decoder_layers=num_decoder_layers,
                         use_layer_norm=use_layer_norm,
                         use_future_features=use_future_features,
                         dropout=dropout)

        input_len, input_size = input_shape
        output_len, target_size = output_shape
        feature_size = (input_size - target_size)

        if decoder_output_size is None:
            decoder_output_size = (feature_size + target_size)//2

        encoder_input_size = input_len * feature_size + input_len * target_size + (
            output_len * feature_size if use_future_features else 0
        )

        temporal_input_shape = (output_len, decoder_output_size + feature_size) \
            if use_future_features else (output_len, decoder_output_size)

        decoder_output_dim = (output_len, decoder_output_size)

        if hidden_size is None:
            hidden_size = encoder_input_size//2

        if temporal_hidden_size is None:
            temporal_hidden_size = decoder_output_size

        self.feature_size = feature_size
        self.hidden_size = hidden_size
        self.decoder_output_size = decoder_output_size
        self.temporal_hidden_size = temporal_hidden_size
        self.num_encoder_layers = num_encoder_layers
        self.num_decoder_layers = num_decoder_layers
        self.use_future_features = use_future_features

        # -------------------------------------------------------------------
        # model

        self.encoders = nn.Sequential(
            _ResidualBlock(
                input_dim=encoder_input_size,
                hidden_size=hidden_size,
                output_dim=hidden_size,
                use_layer_norm=use_layer_norm,
                dropout=dropout,
            ),
            *[
                _ResidualBlock(
                    input_dim=hidden_size,
                    hidden_size=hidden_size,
                    output_dim=hidden_size,
                    use_layer_norm=use_layer_norm,
                    dropout=dropout,
                )
                for _ in range(num_encoder_layers - 1)
            ],
        )

        self.decoders = nn.Sequential(
            *[
                _ResidualBlock(
                    input_dim=hidden_size,
                    hidden_size=hidden_size,
                    output_dim=hidden_size,
                    use_layer_norm=use_layer_norm,
                    dropout=dropout,
                )
                for _ in range(num_decoder_layers - 1)
            ],
            # add decoder output layer
            _ResidualBlock(
                input_dim=hidden_size,
                hidden_size=hidden_size,
                output_dim=decoder_output_dim,
                use_layer_norm=use_layer_norm,
                dropout=dropout,
            ),
        )

        self.temporal_decoder = _ResidualBlock(
            input_dim=temporal_input_shape,
            hidden_size=temporal_hidden_size,
            output_dim=output_shape,
            use_layer_norm=use_layer_norm,
            dropout=dropout,
        )

        self.lookback_skip = nnx.Linear(
            in_features=(input_len, target_size),
            out_features=output_shape
        )
    # end

    def forward(self, x):
        if self.use_future_features:
            assert isinstance(x, (list, tuple))
        else:
            assert isinstance(x, Tensor)

        # concatenate and flatten: return [Xy;Xf], Xf
        xc, yp, xf = self._concat_split_flatten(x)
        # encode
        xe = self.encoders(xc)
        # decode:  (N, output_len, decoder_output_size)
        xg = self.decoders(xe)

        # compose xgf as stack of
        #       xg (N, output_len, decoder_output_size)
        #       xf (N, output_len, feature_size)
        if xf is not None:
            xg = torch.concat([xg, xf], dim=2)

        # apply the temporal decoder
        yt = self.temporal_decoder(xg)

        # apply the lookback skip
        yr = self.lookback_skip(yp)

        # add the residual
        ypred = yt + yr

        return ypred
    # end

    def _concat_split_flatten(self, x):
        # x: (Xy_past, X_future)
        target_size = self.output_shape[1]

        if self.use_future_features:
            Xyp, Xf = x
            yp = Xyp[:, :, -target_size:]

            Xypf = torch.flatten(Xyp, start_dim=1)
            Xff = torch.flatten(Xf, start_dim=1)
            xc = torch.concat([Xypf, Xff], dim=1)
            return xc, yp, Xf
        else:
            Xyp = x
            yp = Xyp[:, :, -target_size:]
            xc = torch.flatten(Xyp, start_dim=1)
            return xc, yp, None
    # end
# end


class TSTiDE(TiDE):
    def __init__(self, input_shape, output_shape,
                 feature_size=None,
                 hidden_size=None,
                 decoder_output_size=None,
                 temporal_hidden_size=None,
                 num_encoder_layers=1,
                 num_decoder_layers=1,
                 use_layer_norm=True,
                 use_future_features=True,
                 dropout=0.1
                 ):
        super().__init__(**locals())

    def forward(self, x: Tensor) -> Tensor:
        return super().forward(x)
# end

# ---------------------------------------------------------------------------
# End
# ---------------------------------------------------------------------------
